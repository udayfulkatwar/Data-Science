{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dddbafc",
   "metadata": {},
   "source": [
    "# NLP Text Summarization\n",
    "\n",
    "This notebook demonstrates a simple extractive text summarization pipeline using NLTK: tokenization, stopword removal, stemming, frequency scoring, and selecting top sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b7d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3df06392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download required NLTK resources (only run once)\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)  # for newer NLTK versions\n",
    "nltk.download('stopwords', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2675d6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " Natural Language Processing (NLP) is a field of Artificial Intelligence \n",
      "that enables computers to understand, interpret, and generate human language. \n",
      "NLP combines computational linguistics with machine learning and deep learning models. \n",
      "Applications of NLP include machine translation, sentiment analysis, and text summarization. \n",
      "Text summarization is a process of creating a short and coherent version of a longer document. \n",
      "It aims to capture the most important information while maintaining the original meaning.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Input Text\n",
    "text = \"\"\"Natural Language Processing (NLP) is a field of Artificial Intelligence \n",
    "that enables computers to understand, interpret, and generate human language. \n",
    "NLP combines computational linguistics with machine learning and deep learning models. \n",
    "Applications of NLP include machine translation, sentiment analysis, and text summarization. \n",
    "Text summarization is a process of creating a short and coherent version of a longer document. \n",
    "It aims to capture the most important information while maintaining the original meaning.\"\"\"\n",
    "\n",
    "print(\"Original Text:\\n\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f501be5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence Tokenization:\n",
      " ['Natural Language Processing (NLP) is a field of Artificial Intelligence \\nthat enables computers to understand, interpret, and generate human language.', 'NLP combines computational linguistics with machine learning and deep learning models.', 'Applications of NLP include machine translation, sentiment analysis, and text summarization.', 'Text summarization is a process of creating a short and coherent version of a longer document.', 'It aims to capture the most important information while maintaining the original meaning.']\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Sentence Tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"\\nSentence Tokenization:\\n\", sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cc5b5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Tokenization:\n",
      " ['natural', 'language', 'processing', '(', 'nlp', ')', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'enables', 'computers', 'to', 'understand', ',', 'interpret', ','] ...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Word Tokenization\n",
    "words = word_tokenize(text.lower())\n",
    "print(\"\\nWord Tokenization:\\n\", words[:20], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f9c11ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Stopword Removal:\n",
      " ['natural', 'language', 'processing', 'nlp', 'field', 'artificial', 'intelligence', 'enables', 'computers', 'understand', 'interpret', 'generate', 'human', 'language', 'nlp', 'combines', 'computational', 'linguistics', 'machine', 'learning'] ...\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Stopword Removal\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "filtered_words = [word for word in words if word not in stop_words and word not in punctuation]\n",
    "print(\"\\nAfter Stopword Removal:\\n\", filtered_words[:20], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96181859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Stemming:\n",
      " ['natur', 'languag', 'process', 'nlp', 'field', 'artifici', 'intellig', 'enabl', 'comput', 'understand', 'interpret', 'gener', 'human', 'languag', 'nlp', 'combin', 'comput', 'linguist', 'machin', 'learn'] ...\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Stemming\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
    "print(\"\\nAfter Stemming:\\n\", stemmed_words[:20], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d459a3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Frequencies:\n",
      " {'natur': 0.3333333333333333, 'languag': 0.6666666666666666, 'process': 0.6666666666666666, 'nlp': 1.0, 'field': 0.3333333333333333, 'artifici': 0.3333333333333333, 'intellig': 0.3333333333333333, 'enabl': 0.3333333333333333, 'comput': 0.6666666666666666, 'understand': 0.3333333333333333, 'interpret': 0.3333333333333333, 'gener': 0.3333333333333333, 'human': 0.3333333333333333, 'combin': 0.3333333333333333, 'linguist': 0.3333333333333333, 'machin': 0.6666666666666666, 'learn': 0.6666666666666666, 'deep': 0.3333333333333333, 'model': 0.3333333333333333, 'applic': 0.3333333333333333, 'includ': 0.3333333333333333, 'translat': 0.3333333333333333, 'sentiment': 0.3333333333333333, 'analysi': 0.3333333333333333, 'text': 0.6666666666666666, 'summar': 0.6666666666666666, 'creat': 0.3333333333333333, 'short': 0.3333333333333333, 'coher': 0.3333333333333333, 'version': 0.3333333333333333, 'longer': 0.3333333333333333, 'document': 0.3333333333333333, 'aim': 0.3333333333333333, 'captur': 0.3333333333333333, 'import': 0.3333333333333333, 'inform': 0.3333333333333333, 'maintain': 0.3333333333333333, 'origin': 0.3333333333333333, 'mean': 0.3333333333333333}\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Frequency Distribution\n",
    "word_freq = {}\n",
    "for word in stemmed_words:\n",
    "    word_freq[word] = word_freq.get(word, 0) + 1\n",
    "\n",
    "# Normalize frequencies\n",
    "max_freq = max(word_freq.values()) if word_freq else 1\n",
    "for word in list(word_freq.keys()):\n",
    "    word_freq[word] = word_freq[word] / max_freq\n",
    "\n",
    "print(\"\\nWord Frequencies:\\n\", word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502cc5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence Scores:\n",
      " {'Natural Language Processing (NLP) is a field of Artificial Intelligence \\nthat enables computers to understand, interpret, and generate human language.': 2.333333333333333, 'NLP combines computational linguistics with machine learning and deep learning models.': 1.3333333333333333, 'Applications of NLP include machine translation, sentiment analysis, and text summarization.': 2.0, 'Text summarization is a process of creating a short and coherent version of a longer document.': 2.6666666666666665}\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Sentence Scoring\n",
    "sentence_scores = {}\n",
    "for sent in sentences:\n",
    "    for word in word_tokenize(sent.lower()):\n",
    "        if word in word_freq:\n",
    "            sentence_scores[sent] = sentence_scores.get(sent, 0) + word_freq[word]\n",
    "\n",
    "print(\"\\nSentence Scores:\\n\", sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c64a34c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- SUMMARY -----\n",
      "\n",
      "Text summarization is a process of creating a short and coherent version of a longer document. Natural Language Processing (NLP) is a field of Artificial Intelligence \n",
      "that enables computers to understand, interpret, and generate human language.\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Generate Summary (Top N sentences)\n",
    "import heapq\n",
    "summary_sentences = heapq.nlargest(2, sentence_scores, key=sentence_scores.get)\n",
    "summary = \" \".join(summary_sentences)\n",
    "\n",
    "print(\"\\n----- SUMMARY -----\\n\")\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
